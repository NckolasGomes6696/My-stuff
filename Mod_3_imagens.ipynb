{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NckolasGomes6696/IPet/blob/main/Mod_3_imagens.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4KQhDikTY3-"
      },
      "source": [
        "### Face and Eye Recognition\n",
        "Before we discuss redaction, lets cover the basics of identifying a face within an image.\n",
        "\n",
        "Within OpenCV-Python, we can use the cv2.rectangle method to draw a rectangle over an image. We need five parameters for this function: image, start_point, end_point, color, and thickness.\n",
        "\n",
        "We can get the start and end points by running a classier to identify the area that contains the face. The code block below uses the haarcascade classifier.  Images must be converted to grayscale before applying the classifier.  The end result is the detectmultiscale function returns an array that correspond to the coordinates for the rectangle that you will input in the opencv rectangle function.\n",
        "\n",
        "A similar pattern is performed to identify any other features such as the eyes which is done in the code block below. We draw the rectangles for the face and eye over the original image and display it in a widget.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545,
          "referenced_widgets": [
            "81403296b2644ef6a70a80665c2685f0",
            "c3d1aa7884624f9cbb1828528c31f01d",
            "3dcf490ff431403b8bceceb8c903ce0c",
            "1756aaf3f84748aab1a05d8e3265f2bc"
          ]
        },
        "id": "JQXjqVFdTY4F",
        "outputId": "e24ddf81-1315-4379-f311-27ca8cd479cb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x08\\x02\\x00\\x00\\x00\\xd3\\x10?…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "81403296b2644ef6a70a80665c2685f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x08\\x02\\x00\\x00\\x00\\xd3\\x10?…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3dcf490ff431403b8bceceb8c903ce0c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#https://www.geeksforgeeks.org/how-to-blur-faces-in-images-using-opencv-in-python/\n",
        "#https://docs.opencv.org/3.1.0/d7/d8b/tutorial_py_face_detection.html#gsc.tab=0\n",
        "# Importing libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "import ipywidgets\n",
        "from IPython.display import display\n",
        "#from google.colab.patches import cv2_imshow\n",
        "\n",
        "# A function for plotting the images\n",
        "\n",
        "oimage_widget = ipywidgets.Image(format='png')\n",
        "image_widget = ipywidgets.Image(format='png')\n",
        "# Reading an image using OpenCV\n",
        "# OpenCV reads images by default in BGR format\n",
        "image = cv2.imread('/content/lena_color.png')\n",
        "\n",
        "# Converting BGR image into a RGB image\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# plotting the original image\n",
        "oimage = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "oimage_widget.value = bytes(cv2.imencode('.png', oimage)[1])\n",
        "display(oimage_widget)\n",
        "\n",
        "#need to ensure this matches the actual file locations!\n",
        "fpath='/content/cascades/haarcascade_frontalface_alt.xml'\n",
        "epath='/content/cascades/haarcascade_eye.xml'\n",
        "\n",
        "face_detect = cv2.CascadeClassifier(fpath)\n",
        "eye_detect = cv2.CascadeClassifier(epath)\n",
        "\n",
        "#returns an array that identifies the four points that contain the face\n",
        "faces = face_detect.detectMultiScale(gray, 1.3, 5)\n",
        "for (x,y,w,h) in faces:\n",
        "    cv2.rectangle(image,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "    roi_gray = gray[y:y+h, x:x+w]\n",
        "    roi_color = image[y:y+h, x:x+w]\n",
        "    eyes = eye_detect.detectMultiScale(roi_gray)\n",
        "    for (ex,ey,ew,eh) in eyes:\n",
        "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
        "\n",
        "\n",
        "# Display the output\n",
        "image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "image_widget.value = bytes(cv2.imencode('.png', image)[1])\n",
        "display(image_widget)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NISgVYH4TY4O"
      },
      "source": [
        "### Redact an image - CPU\n",
        "Now lets blur the are within the rectangle to redact the face using the OpenCV GaussianBlur function. We will not identify eyes in this code block, just the face."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316,
          "referenced_widgets": [
            "788d6505e38c4a1180d4643e300f33e8",
            "75feac1580ac4b119f6e5a8f851124e5"
          ]
        },
        "id": "reFD2NfsTY4Q",
        "outputId": "0438b99e-8ff8-4a2b-c78e-82e992dc00fa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x08\\x02\\x00\\x00\\x00\\xd3\\x10?…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "788d6505e38c4a1180d4643e300f33e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 85.9 ms, sys: 892 µs, total: 86.8 ms\n",
            "Wall time: 73.2 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "import numpy as np\n",
        "import cv2\n",
        "import ipywidgets\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "\n",
        "# Reading an image using OpenCV\n",
        "image = cv2.imread('/content/lena_color.png')\n",
        "image_widget = ipywidgets.Image(format='png')\n",
        "\n",
        "# Converting BGR image into a RGB image\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "fpath='/content/cascades/haarcascade_frontalface_alt.xml'\n",
        "\n",
        "face_detect = cv2.CascadeClassifier(fpath)\n",
        "\n",
        "faces = face_detect.detectMultiScale(gray, 1.3, 5)\n",
        "for (x,y,w,h) in faces:\n",
        "    cv2.rectangle(image,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "    roi_gray = gray[y:y+h, x:x+w]\n",
        "    roi_color = image[y:y+h, x:x+w]\n",
        "    roi = cv2.GaussianBlur(roi_color, (23, 23), 30)\n",
        "    # impose this blurred image on original image to get final image\n",
        "    image[y:y+roi.shape[0], x:x+roi.shape[1]] = roi\n",
        "\n",
        "# Display the output\n",
        "image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "image_widget.value = bytes(cv2.imencode('.png', image)[1])\n",
        "display(image_widget)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image Redaction - Exercise\n",
        "Now let's practice what you have learned.\n",
        "\n",
        "We are going to a variation. Rather than redact the face, let's redact the areas within the eyes.  "
      ],
      "metadata": {
        "id": "6t4tb_Qsj4dZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import cv2\n",
        "import ipywidgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Reading an image using OpenCV\n",
        "image = cv2.imread('/content/lena_color.png')\n",
        "image_widget = ipywidgets.Image(format='png')\n",
        "\n",
        "# Load the pre-trained face and eye cascade classifiers\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
        "\n",
        "# Converting BGR image into an RGB image\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Detect faces in the image\n",
        "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "# Loop over the detected faces\n",
        "for (x, y, w, h) in faces:\n",
        "    roi_gray = gray[y:y + h, x:x + w]\n",
        "    roi_color = image_rgb[y:y + h, x:x + w]\n",
        "\n",
        "    # Detect eyes within the face region\n",
        "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
        "\n",
        "    # Apply Gaussian blur to each detected eye\n",
        "    for (ex, ey, ew, eh) in eyes:\n",
        "        eye_roi = roi_color[ey:ey + eh, ex:ex + ew]\n",
        "        blurred_eye = cv2.GaussianBlur(eye_roi, (23, 23), 30)\n",
        "        roi_color[ey:ey + eh, ex:ex + ew] = blurred_eye\n",
        "\n",
        "# Display the output\n",
        "image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
        "image_widget.value = bytes(cv2.imencode('.png', image_bgr)[1])\n",
        "display(image_widget)"
      ],
      "metadata": {
        "id": "KE9DafhP4uL4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316,
          "referenced_widgets": [
            "4f2299b96b0149a995d6f1e0f6217352",
            "21bb38858faa4d1da19e092f8c1cdccb"
          ]
        },
        "outputId": "ff61b0a7-0520-460d-d7b4-2e1866a227e1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x08\\x02\\x00\\x00\\x00\\xd3\\x10?…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f2299b96b0149a995d6f1e0f6217352"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 110 ms, sys: 4.57 ms, total: 115 ms\n",
            "Wall time: 161 ms\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "81403296b2644ef6a70a80665c2685f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ImageModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ImageModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ImageView",
            "format": "png",
            "height": "",
            "layout": "IPY_MODEL_c3d1aa7884624f9cbb1828528c31f01d",
            "width": ""
          }
        },
        "c3d1aa7884624f9cbb1828528c31f01d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dcf490ff431403b8bceceb8c903ce0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ImageModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ImageModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ImageView",
            "format": "png",
            "height": "",
            "layout": "IPY_MODEL_1756aaf3f84748aab1a05d8e3265f2bc",
            "width": ""
          }
        },
        "1756aaf3f84748aab1a05d8e3265f2bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "788d6505e38c4a1180d4643e300f33e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ImageModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ImageModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ImageView",
            "format": "png",
            "height": "",
            "layout": "IPY_MODEL_75feac1580ac4b119f6e5a8f851124e5",
            "width": ""
          }
        },
        "75feac1580ac4b119f6e5a8f851124e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f2299b96b0149a995d6f1e0f6217352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ImageModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ImageModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ImageView",
            "format": "png",
            "height": "",
            "layout": "IPY_MODEL_21bb38858faa4d1da19e092f8c1cdccb",
            "width": ""
          }
        },
        "21bb38858faa4d1da19e092f8c1cdccb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}