{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NckolasGomes6696/My-stuff/blob/main/Word2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJReOFtyGFSs"
      },
      "source": [
        "# E03 Sistema de Recomendação usando Word2Vec\n",
        "\n",
        "Neste exercício você irá desenvolver um sistema de recomendação usando _embeddings_ criados com Word2Vec. A partir de uma base de dados de _e-commerce_ onde estão registradas as compras de um site de vendas pela internet, vamos avaliar quais mercadorias foram compradas juntamente a quais outras mercadorias. O pressuposto aqui é que quando o cliente realiza uma compra online, ele possui um interesse temático em mente e acaba comprando itens que se correlacionam de alguma forma. Ainda que em alguns casos possam ser incluídos itens menos relacionados, em sua vasta maioria assumimos que as compras seguem algum tipo de correlação entre si. Por exemplo, um cliente pode estar fazendo compras para organizar uma festa infantil ou uma viagem, e de acordo com esse interesse, acaba comprando itens relacionados a essas atividades.\n",
        "\n",
        "Sendo assim, neste exercício, nosso interesse estará em tentar criar um embedding usando o algoritmo Word2Vec, usando como contexto de vizinhança a sequência de produtos comprados por um mesmo cliente em uma específica nota fiscal. Cada ordem de compra (carrinho de compras) vai conter uma lista de produtos, e os códigos de identificação destes produtos serão nossas \"palavras\", sendo que a sequência de produtos comprados formam as \"frases\" para nosso treinamento.\n",
        "\n",
        "Como neste exercício usaremos a biblioteca _gensim_, você perceberá que a parte mais trabalhosa do exercício estará na preparação dos dados, já que a ferramenta que cria o _embedding_ já estará pronta para uso. Então nesse exercício, você ficara encarregado da preparação dos dados.\n",
        "\n",
        "Para resolver o exercício, siga os passos, lendo as instruções e comentários, um a um, e preenchendo código onde for requisitado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEHafkstxrSx"
      },
      "source": [
        "## Passo 1: Baixar Dados\n",
        "\n",
        "Aqui usaremos uma planilha do Microsoft Excel com dados de compras de usuários em um sistema de varejo. O nome do arquivo é `retail.xlsx`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9J6QmO3xJ3t",
        "outputId": "7de1f5a2-92a0-4895-c2da-112c101fd003",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# O comando abaixo baixa o arquivo correspondente a essa planilha\n",
        "# do Excel para o computador remoto do Google Colab.\n",
        "\n",
        "!gdown https://drive.google.com/uc?id=1NK-2z0l-qTplDJJ2SHpTVBGRP3zWAK-n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/gdown\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gdown/cli.py\", line 151, in main\n",
            "    filename = download(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gdown/download.py\", line 203, in download\n",
            "    filename_from_url = m.groups()[0]\n",
            "AttributeError: 'NoneType' object has no attribute 'groups'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFZELJRCyLut"
      },
      "source": [
        "Usaremos a biblioteca `pandas` para fazer a leitura dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_HXamB_yLIi"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQqCAb-3yZRN"
      },
      "source": [
        "Aqui fazemos a leitura dos dados para um objeto `DataFrame` do `pandas`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33NLQ2NgyciL",
        "outputId": "82558750-e4b4-4361-8bd8-520d786d2ebe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        }
      },
      "source": [
        "# Esta linha de código pode demorar cerca de 1 min para rodar\n",
        "df = pd.read_excel('retail.xlsx')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'retail.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-08d68a99678d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Esta linha de código pode demorar cerca de 1 min para rodar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'retail.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1650\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1653\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1523\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1526\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'retail.xlsx'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FLMkSqUyrWa"
      },
      "source": [
        "Agora podemos observar os dados para entender como estão organizados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TE4oGyTqyqdT"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HChM_88szGTN"
      },
      "source": [
        "A tabela acima mostra a estrutura da planilha. Podemos observar os campos:\n",
        "\n",
        "- **InvoiceNo**: Este é um identificador único para cada compra.\n",
        "- **StockCode**: Identificador único para cada produto.\n",
        "- **Description**: Descrição do produto.\n",
        "- **Quantidade**: Quantidade daquele produto, naquela compra.\n",
        "- **InvoiceDate**: Dia e hora da compra.\n",
        "- **CustomerID**: Identificador único do cliente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN-jtPHe0VKz"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfS_FBWK0Y_Y"
      },
      "source": [
        "Acima vemos que essa base de dados possui 541.909 registros. Cada registro representa uma linha, ou seja, um produto comprado (cuja quantidade pode ser maior que 1). Diferentes linhas podem representar diferentes itens de uma mesma compra."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwgPe3f90tSw"
      },
      "source": [
        "## Passo 2: Remoção de Dados Nulos\n",
        "\n",
        "Neste passo vamos remover da base de dados os dados relativos a compras de produtos onde algum dos dados de interesse estejam faltando."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeSIJZ9x1Cuv"
      },
      "source": [
        "Começamos observando a quantidade de dados nulos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJmozJlf1Aze"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWgIGnJL1M9b"
      },
      "source": [
        "Acima podemos observar há 1.454 registros sem a descrição do produto, e 135.080 registros sem a identificação do cliente comprador."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7RR0IK82HuT"
      },
      "source": [
        "No código abaixo você deve remover todos os registros onde aparece pelo menos um dos campos nulos. Para entender como fazer isso, veja esse trecho da videoaula sobre pandas (especificamente a partir de 19m41s no vídeo, até mais ou menos 21m).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-77dPKr1Wcz3"
      },
      "source": [
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('usmbTUx9zdY', start=1181)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZrVo84f2OmJ"
      },
      "source": [
        "# Insira aqui seu código para remover os dados nulos.\n",
        "# Ao final do código, a variável df deve ser um DataFrame\n",
        "# do pandas contendo apenas os registros onde nenhuma\n",
        "# coluna é nula. O resultado deve ser sobrescrito na\n",
        "# na própria variável df. Há duas formas de fazer isso\n",
        "# no pandas\n",
        "#\n",
        "#  Opção 1 Usando inplace: df.função(argumentos, inplace=True)\n",
        "#  Opção 2 Usando atribuição: df = df.função(argumentos)\n",
        "\n",
        "# SEU CÓDIGO AQUI!\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Remover registros onde pelo menos uma coluna é nula\n",
        "df.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJL2FDvJVOF1"
      },
      "source": [
        "# Verifica novamente. Dessa vez os valores\n",
        "# da soma devem estar zerados para todas\n",
        "# colunas.\n",
        "\n",
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlj5sCY7SNs8"
      },
      "source": [
        "## Passo 3: Dicionário de Produtos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xd7p7gROY2Dq"
      },
      "source": [
        "Agora vamos preparar um dicionário de códigos e respectivas descrições dos produtos. Esse dicionário servirá para que nós, humanos, possamos inspecionar o resultado de nossas operações no _embedding_, já que o _embedding_ vai ser treinado com base nos códigos dos produtos. Como os códigos não permitem inspeção intuitiva da natureza de cada produto, vamos precisar desse dicionário para entender qual é a descrição do produto correspondente a cada código."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVIvmK9v3O96"
      },
      "source": [
        "### Passo 3.1: Conversão dos Códigos para Strings\n",
        "\n",
        "Começamos convertendo os códigos de produto (coluna **StockCode**) para string, para usar como \"palavras\" no treinamento de um modelo word2vec no `gensim` mais tarde.\n",
        "\n",
        "Para fazer isso você pode usar o método `.astype(tipo)` do pandas. Com esse comando, você consegue converter uma coluna específica do DataFrame para o tipo de dado que quiser. Por exemplo, se tivéssemos um DataFrame `d` com uma coluna chamada `idade` no formato `int` e se quiséssemos converter para o formato `float`, bastaria executar o comando:\n",
        "\n",
        "`# Converte idade para float`\n",
        "\n",
        "`d['idade'] = d['idade'].astype(float)`\n",
        "\n",
        "No nosso caso, queremos transformar o campo `StockCode` do DataFrame `df` para o formato string (`str`). Após a alteração, os elementos da coluna `StockCode` de `df` deverão ser strings.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wvr77qNr2yKh"
      },
      "source": [
        "# Escreva abaixo seu código para converter os códigos\n",
        "# de produtos (campo 'StockCode') para o formato string\n",
        "# no DataFrame df.\n",
        "\n",
        "# SEU CÓDIGO AQUI!\n",
        "\n",
        "import pandas as pd\n",
        "# Converter 'StockCode' para o formato de string\n",
        "df['StockCode'] = df['StockCode'].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HLn63a1TYfX"
      },
      "source": [
        "### Passo 3.2\n",
        "\n",
        "Agora criaremos um novo _DataFrame_, de nome `products`. Selecionaremos apenas as colunas `StockCode` e `Description` do _DataFrame_ original, `df`.\n",
        "\n",
        "Para entender como selecionar colunas específicas, veja o vídeo abaixo a partir de 21m07s até 21m35s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suIsqNd2Z-qL"
      },
      "source": [
        "YouTubeVideo('usmbTUx9zdY', start=1267)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdB8mxOuy4bl"
      },
      "source": [
        "Escreva seu código abaixo, criando o `DataFrame` de nome `products` que seleciona apenas as colunas `StockCode` e `Description`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZhbpw2PSUUL"
      },
      "source": [
        "# Escreva aqui abaixo seu código para separar apenas\n",
        "# as colunas de código de produto, nome 'StockCode'\n",
        "# e descrição, nome 'Description'. O novo DataFrame\n",
        "# deve ser gravado na variável de nome products.\n",
        "\n",
        "# SEU CÓDIGO AQUI!\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Criar o novo DataFrame 'products' com as colunas 'StockCode' e 'Description'\n",
        "products = df.loc[:, ['StockCode', 'Description']]\n",
        "\n",
        "# Exibir as primeiras linhas do novo DataFrame\n",
        "print(products.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzMELP7uzeUM"
      },
      "source": [
        "### Passo 3.3 Remoção de Itens Duplicados\n",
        "\n",
        "Obviamente muitos produtos foram comprados mais de uma vez. Em nosso dicionário de códigos e descrições, como a finalidade é simplesmente identificar a descrição que corresponde a um determinado código, então não faz sentido ter itens duplicados.\n",
        "\n",
        "No código abaixo faça uma remoção de todas entradas onde o código do produto (coluna `StockCode`) seja duplicado.\n",
        "\n",
        "Para entender como fazer isso, veja o vídeo abaixo a partir de 21m41s até 22m10s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y20WJ3up0nLO"
      },
      "source": [
        "YouTubeVideo('usmbTUx9zdY', start=1301)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtdlOtbOzIJ8"
      },
      "source": [
        "# Escreva abaixo o código para remover os itens duplicados\n",
        "# do DataFrame de produtos. Ao fazer isso garanta que o nome\n",
        "# do DataFrame seja o mesmo, ou seja, o resultado deve ser\n",
        "# gravado na própria variável products.\n",
        "\n",
        "# SEU CÓDIGO AQUI!\n",
        "\n",
        "# Remover itens duplicados e atualizar a variável products\n",
        "products = products.drop_duplicates()\n",
        "\n",
        "# Exibir as primeiras linhas do DataFrame após a remoção de duplicatas\n",
        "print(products.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_Zh1f1P1MfN"
      },
      "source": [
        "### Passo 3.4 Criação do Dicionário\n",
        "\n",
        "Agora você vai criar um dicionário nativo do Python, onde as chaves serão os códigos dos produtos (`StockCode`) e os valores serão as respectivas strings de descrição (`Description`).\n",
        "\n",
        "Para entender como converter este DataFrame em um dicionário, assista o vídeo abaixo, a partir de 22min35s até 23min03s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkNkTizRvFu_"
      },
      "source": [
        "YouTubeVideo('usmbTUx9zdY', start=1355)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "An0BgKa91RTl"
      },
      "source": [
        "# Escreva aqui seu código para criar um dicionário do\n",
        "# Python a partir do DataFrame products. O nome do\n",
        "# dicionário deverá ser prodcuts_dict\n",
        "\n",
        "# SEU CÓDIGO AQUI!\n",
        "\n",
        "# Supondo que 'StockCode' seja a chave e 'Description' seja o valor\n",
        "products_dict = products.set_index('StockCode')['Description'].to_dict()\n",
        "\n",
        "# Exibindo o dicionário\n",
        "print(products_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GtvB9h7Sm-1"
      },
      "source": [
        "# Teste do dicionário: na linha de código abaixo\n",
        "# consultamos um código de produto no seu dicionário.\n",
        "# Se você cumpriu todos passos corretamente até\n",
        "# aqui, então o resultado deve ser uma lista contendo\n",
        "# uma única string, que é a descrição do produto\n",
        "# correspondente àquele código.\n",
        "\n",
        "products_dict['84029E']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzH4dqdM2bPg"
      },
      "source": [
        "## Passo 4: Preparação dos Dados\n",
        "\n",
        "Neste passo vamos preprarar os dados transformando o histórico de compras de cada consumidor numa espécie de \"frase\", onde cada \"palavra\" é um produto comprado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qev247Zd3fq2"
      },
      "source": [
        "### Passo 4.1: Contagem dos Clientes Únicos\n",
        "\n",
        "Nesta base de dados temos o registro de cada compra de cada cliente ao longo de um ano. Isso significa que não apenas podemos ter o mesmo produto sendo comprado por diferentes clientes, mas também teremos o mesmo cliente, fazendo diferentes compras em diferentes momentos.\n",
        "\n",
        "Para avaliar nosso sistema de forma mais justa e próxima de um uso real, vamos tentar separar dados de validação e dados de treinamento de forma que não usemos compras de um mesmo cliente nos dados de validação e nos dados de treinamento (mesmo que em momentos diferentes). Em outras palavras, vamos separar _todas as compras_ de certos clientes para treinamento e _todas as compras_ de certos outros clientes para validação, ou seja, a separação será pelo cliente que realizou a compra. Assim todas compras de um determinado cliente estarão exclusivamente nos dados de validação ou exclusivamente nos dados de treinamento, nunca em ambos. Isso servirá para que possamos avaliar se o sistema de recomendação funciona, mesmo quando treinado para clientes diferentes daqueles para os quais estamos recomendando no momento: quer dizer que podemos treinar o sistema com as compras dos clientes escolhidos para o grupo de treinamento e avaliar as recomendações num grupo de clientes que o sistema nunca viu antes.\n",
        "\n",
        "Para fazer isso, seria interessante começar confirmando exatamente quantos clientes únicos temos nessa base de dados.\n",
        "\n",
        "A partir do DataFrame `df` selecione a coluna `CustomerID` e usando os métodos `unique()` e a conversão `tolist()`, gere uma lista com todos os ids de clientes únicos. Essa lista deverá se chamar `customers`.\n",
        "\n",
        "O vídeo abaixo, a partir de 23m59s até 25m16s, mostra como isso pode ser feito."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVQZtVkT0Mqh"
      },
      "source": [
        "YouTubeVideo('usmbTUx9zdY', start=1439)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLGQA2VZ3lpc"
      },
      "source": [
        "# Escreva abaixo o código que cria uma lista\n",
        "# coletando os ids da coluna CustomerID de df,\n",
        "# selecionando apenas ids únicos (não recolhe\n",
        "# ids repetidos). Esta lista deve ser uma lista\n",
        "# nativa do Python, de nome customers.\n",
        "\n",
        "# SEU CÓDIGO AQUI!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em6vNYCjzU8K"
      },
      "source": [
        "len(customers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZTGaq3n35dn"
      },
      "source": [
        "Se tudo deu certo até aqui, então verificamos que há exatamente 4.372 clientes na nossa base de dados. Para cada um desses clientes vamos verificar o histórico de compras, criando 4.372 sequências de compras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIMP9AOiHWOr"
      },
      "source": [
        "### Passo 4.2: Embaralhamento dos Dados\n",
        "\n",
        "Agora escreva código para embaralhar a ordem dos ids dos clientes na lista `customers`, usando o método `shuffle`. O resultado deve estar na própria variável `customers` (não mude o nome da variável)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvRoZx2wHOXv"
      },
      "source": [
        "# No espaço abaixo, importe o módulo random\n",
        "# e chame a função shuffle embaralhando os\n",
        "# itens na lista customers\n",
        "\n",
        "# SEU CÓDIGO AQUI!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQYdfD3RJI75"
      },
      "source": [
        "### Passo 4.3: Separação dos Dados de Treinamento e Validação\n",
        "\n",
        "Agora vamos separar dados de treinamento e de validação. Vamos separar 10% dos dados para validação e 90% dos dados para treinamento. Mas esses percentuais serão separados em termos de clientes. Isso significa que faremos o seguinte:\n",
        "\n",
        "1. Definiremos uma lista de clientes de treinamento, contendo 90% dos itens da variável `customers`. Vamos chamar essa variável de `customers_train`.\n",
        "2. Definiremos uma lista de clientes de validação, contendo 10% dos itens da variável `customers`. Vamos chamar essa variável de `customers_val`.\n",
        "3. Em nosso dataset `df`, selecionaremos todas as linhas onde o campo `CustomerID` contenha um código de cliente presente na lista `customers_train`. Essa seleção será um novo dataset de nome `df_train`.\n",
        "4. Faremos o mesmo com os  dados de validação,  selecionando as linhas de `df` onde `CustomerID` está contido em `customers_val`. Essa seleção chamaremos de `df_val`.\n",
        "\n",
        "Dica: para os passos 3 e 4 acima, use o método `.isin(nome_da_lista)`. Veja o vídeo abaixo a partir de 25m19s até o final do vídeo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckUuDo_JYF5l"
      },
      "source": [
        "YouTubeVideo('usmbTUx9zdY', start=1519)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq6yEiaQJIjr"
      },
      "source": [
        "# Calcule a quantidade de clientes que usaremos\n",
        "# para treinamento. Essa quantidade deve ser 90%\n",
        "# do total de clientes na variável customers.\n",
        "# Transforme o resultado em um número inteiro.\n",
        "# O resultado deve ser gravado na variável de\n",
        "# nome train_size.\n",
        "\n",
        "# SEU CÓDIGO AQUI!\n",
        "\n",
        "# Calcular o tamanho do conjunto de treinamento (90% do total de clientes)\n",
        "train_size = int(len(customers) * 0.9)\n",
        "\n",
        "# Exibir o tamanho do conjunto de treinamento\n",
        "print(\"Tamanho do conjunto de treinamento:\", train_size)\n",
        "\n",
        "# Use o slicing do Python para separar\n",
        "# os consumidores em duas listas: uma para\n",
        "# treinamento e a outra para validação. Para\n",
        "# definir o ponto de corte do slicing, use\n",
        "# a variável train_size definida acima. A lista\n",
        "# de consumidores para treinamento deve se\n",
        "# chamar customers_train e incluir exatamente\n",
        "# o trecho da lista customers começando\n",
        "# do início, com quantidade igual a train_size.\n",
        "# Os demais devem itens ser colocados na lista\n",
        "# de nome customers_val (lista ids de validação)\n",
        "\n",
        "# SEU CÓDIGO AQUI!\n",
        "\n",
        "\n",
        "# Separar os consumidores em duas listas: treinamento e validação\n",
        "customers_train = customers[:train_size]\n",
        "customers_val = customers[train_size:]\n",
        "\n",
        "# Exibir as primeiras linhas de ambas as listas\n",
        "print(\"Lista de consumidores para treinamento:\", customers_train[:5])\n",
        "print(\"Lista de consumidores para validação:\", customers_val[:5])\n",
        "\n",
        "# Agora, baseado nos ids separados nas listas\n",
        "# customers_train e customers_val acima, crie\n",
        "# dois datasets a partir do dataset original df,\n",
        "# selecionando em df_train as linhas que contem\n",
        "# ids da lista customers_train no campo CustomerID,\n",
        "# e em df_val as linhas que contem  ids da lista\n",
        "# customers_val.\n",
        "\n",
        "# SEU CÓDIGO AQUI!\n",
        "\n",
        "# Criar df_train selecionando as linhas com CustomerID em customers_train\n",
        "df_train = df[df['CustomerID'].isin(customers_train)]\n",
        "\n",
        "# Criar df_val selecionando as linhas com CustomerID em customers_val\n",
        "df_val = df[df['CustomerID'].isin(customers_val)]\n",
        "\n",
        "# Exibir as primeiras linhas de ambos os datasets\n",
        "print(\"df_train:\")\n",
        "print(df_train.head())\n",
        "\n",
        "print(\"\\ndf_val:\")\n",
        "print(df_val.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPSvCp8LKB5n"
      },
      "source": [
        "### Passo 4.4: Função que compila sequência de compras de cada cliente.\n",
        "\n",
        "Com essas listas de clientes criamos abaixo as sequências de compras de acordo com os históricos de cada cliente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp8qT1FJKPY2"
      },
      "source": [
        "def compile_orders(customers, df):\n",
        "  ''' Essa função coleta todas compras do histórico\n",
        "      de cada cliente. O parâmetro customers é a lista\n",
        "      de ids de clientes e o parâmetro df é o objeto\n",
        "      DataFrame do pandas com os dados de cada compra.\n",
        "      O valor retornado é uma lista de listas, onde cada\n",
        "      lista interna contém a seguência de códigos de produto\n",
        "      de cada compra, na ordem que se apresentava no\n",
        "      histórico.\n",
        "  '''\n",
        "\n",
        "  # Essa será a lista de compras -- lista de listas de produtos\n",
        "  orders = []\n",
        "\n",
        "  # Coletaremos as compras de cada cliente\n",
        "  for customer in customers:\n",
        "\n",
        "    # Aqui convertemos os códigos de produtos das compras\n",
        "    # de cada cliente para uma lista única\n",
        "    order = df[df['CustomerID'] == customer]['StockCode'].tolist()\n",
        "\n",
        "    # Essa lista de itens será a lista de produtos que será adicionada\n",
        "    # à lista de compras principal.\n",
        "    orders.append(order)\n",
        "\n",
        "  return orders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaIkbOMiM2ne"
      },
      "source": [
        "# Aqui separamos as listas de listas de compras. Este código\n",
        "# demora cerca de 1 minuto para rodar\n",
        "orders_train = compile_orders(customers_train, df_train)\n",
        "orders_val = compile_orders(customers_val, df_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCqVu7rsQDeQ"
      },
      "source": [
        "## Passo 5: Treinar o Embedding Word2Vec\n",
        "\n",
        "Esta é a última etapa, onde utilizamos a lista de compras (lista de listas com códigos de produtos) para treinar nosso embedding. Essa lista de listas funcionará de forma análoga a uma lista de frases, onde cada frase é uma lista de palavras: lista de listas de palavras. A diferença é que aqui as strings que seriam palavras foram substituídas por códigos de produtos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u49iedUAQThF"
      },
      "source": [
        "# Aqui importamos o módulo GenSim\n",
        "import gensim\n",
        "\n",
        "# Importamos o NumPy\n",
        "import numpy as np\n",
        "\n",
        "# Código para ignorar warnings\n",
        "# (só para 'despoluir' as saídas\n",
        "#  por motivos didáticos, ignorar\n",
        "#  warnings não é prática recomendada\n",
        "#  exceto quando o código já foi\n",
        "#  testado e os warnings examinados\n",
        "#  e determinados como seguros)\n",
        "import warnings;\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWoNEmF9Q99o"
      },
      "source": [
        "# Criamos o objeto da classe Word2Vec. Já no\n",
        "# construtor passamos os parâmetros de treinamento,\n",
        "# pois o modelo será treinado ao criar o objeto.\n",
        "\n",
        "model = gensim.models.Word2Vec(orders_train, \\\n",
        "                               size=50, \\\n",
        "                               window=5, \\\n",
        "                               workers=10, \\\n",
        "                               iter=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRUDgNq6Rd-_"
      },
      "source": [
        "# Mostra os dados básicos do objeto\n",
        "\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHWIan6WBhU4"
      },
      "source": [
        "## Passo 5: Resultados\n",
        "\n",
        "Finalmente podemos agora examinar como ficou o resultado.\n",
        "\n",
        "### Passo 5.1: Produtos semelhantes\n",
        "\n",
        "Para facilitar nossos testes, definimos abaixo uma função que retorna os 10 produtos mais semelhantes a um produto específico, passado como argumento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8o6X7LbSxM3"
      },
      "source": [
        "def most_similar(product_id):\n",
        "  ''' Essa função mostra os 10 produtos mais semelhantes\n",
        "      ao produto cujo código foi passado como argumento.\n",
        "      Na verdade o método most_similar() do objeto Word2Vec\n",
        "      já faz isso. Aqui apenas acrescentamos as descrições,\n",
        "      para facilitar examinar o resultado, já que olhando\n",
        "      apenas os códigos ficaria difícil de dizer se o\n",
        "      conjunto de produtos semelhantes faz sentido.\n",
        "  '''\n",
        "\n",
        "  # Primeiro mostramos a descrição do produto consultado\n",
        "  print('Most similar to:', products_dict[product_id])\n",
        "\n",
        "  # Aqui buscamos a lista de códigos mais semelhantes\n",
        "  # ao apresentado no embedding.\n",
        "  s = model.most_similar(positive=product_id)\n",
        "\n",
        "  # Para cada código, mostramos a descrição\n",
        "  for product, prob in s:\n",
        "    print(products_dict[product], prob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPUMtcNgJY8Q"
      },
      "source": [
        "model.wv.index2entity[1000:1010]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxfEa_-bKAQd"
      },
      "source": [
        "products_dict.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJyuZm-6UKeP"
      },
      "source": [
        "# Aqui vamos verificar o produto mais semelhante\n",
        "# ao produto de código 23188.\n",
        "\n",
        "most_similar('23188')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8LcgPfnCw4m"
      },
      "source": [
        "## Passo 5.2: Sugestão de produtos\n",
        "\n",
        "Agora sim, podemos fazer nosso sistema de sugestões de compras. Na variável orders_val temos os conjuntos de itens em cada compra, de cada cliente. Por exemplo, abaixo, podemos listar as compras da ordem número 32, no código abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41eY2zY1UjIT"
      },
      "source": [
        "# Lista os códigos dos produtos comprados\n",
        "# na ordem de compras número 32.\n",
        "\n",
        "orders_val[32]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaQ58JsNDY5i"
      },
      "source": [
        "Para sugerir compras, basta recuperarmos os vetores de embedding de cada um desses itens de uma ordem de compra, calcular um vetor médio (soma todos vetores e divide pela quantidade) e buscar os produtos mais semelhantes, como fizemos antes!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Me8QvWIVXi-"
      },
      "source": [
        "def get_suggestions(orders):\n",
        "  ''' Nesta função, passa-se como argumento uma lista\n",
        "      de códigos de produtos, que representa as compras\n",
        "      de um cliente, em um determinado momento. Com base\n",
        "      nos embeddings desses itens, calculamos um vetor\n",
        "      médio, que captura a \"semântica\" das compras e\n",
        "      baseado nesse vetor, buscamos os produtos mais\n",
        "      similares para sugerir. Apenas sugerimos os\n",
        "      produtos que já não estiverem na lista.\n",
        "  '''\n",
        "  # Esse será o array que armazenará o embedding médio\n",
        "  v = np.zeros((50))\n",
        "\n",
        "  # Essa variável vai receber a quantidade de produtos,\n",
        "  # para calcular a média mais tarde.\n",
        "  count = 0\n",
        "\n",
        "  # Aqui mostramos as descrições dos produtos já na lista\n",
        "  # para facilitar a conferência.\n",
        "  print('Orders so far:')\n",
        "  for product in orders:\n",
        "    print(products_dict[product])\n",
        "    # Para cada produto no embedding (aqui testamos,\n",
        "    # para evitar incluir um produto que não esteja\n",
        "    # no embedding treinado, pois isso geraria um erro)\n",
        "    if product in model.wv:\n",
        "      # somamos o vetor de embedding daquele produto\n",
        "      # no array v\n",
        "      v += model.wv[product]\n",
        "      # e contamos +1 em count\n",
        "      count += 1\n",
        "  # Dividmos o resultado por count para calcular\n",
        "  # o vetor médio, no espaço de embeddings\n",
        "  v /= count\n",
        "  # E por fim buscamos os 10 produtos mais semelhantes\n",
        "  # como fizemos originalmente.\n",
        "  s = model.wv.similar_by_vector(v)\n",
        "  print('Suggestions:')\n",
        "  for product, prob in s:\n",
        "    # Mostramos apenas os produtos que já não estiverem\n",
        "    # na lista original.\n",
        "    if product not in orders:\n",
        "      # Mostramos as descrições para facilitar a leitura\n",
        "      print(products_dict[product], prob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-i31ZVGuFCH7"
      },
      "source": [
        "Abaixo testamos o código de sugestões definido acima."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEku0QXUXhxp"
      },
      "source": [
        "get_suggestions(orders_val[32])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DzmHZYJVu5N"
      },
      "source": [
        "get_suggestions(orders_val[67])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6rk6No3XkpS"
      },
      "source": [
        "get_suggestions(orders_val[88])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}